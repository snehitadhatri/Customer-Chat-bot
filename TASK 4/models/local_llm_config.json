{
"model_name": "TheBloke/Llama-2-7B-GGML",
"backend": "transformers",
"device": "cuda",
"max_new_tokens": 512,
"temperature": 0.7,
"top_p": 0.9,
"context_window": 2048,
"use_4bit": true
}
